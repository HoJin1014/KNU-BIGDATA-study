{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 개발 코드\n",
    "- 로컬에서 주피터 노트북(Jupyter Notebook), 주피터 랩(JupyterLab) 또는 파이썬(Python)을 이용한다. \n",
    "- 사이킷 런(scikit-learn), 텐서플로우(tensorflow), 파이토치(pytorch)를 사용하여 딥러닝 프로그램을 개발한다.\n",
    "- 파일명: 0_local_text_generation.ipynb\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. **데이터셋 준비(Data Setup)**\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터셋을 준비한다.\n",
    "\n",
    "2. **데이터 전처리(Data Preprocessing)**\n",
    "- 데이터셋의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. **학습 모델 훈련(Train Model)**\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터셋으로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. **추론(Inference)**\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터셋을 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 생성(Text Generation)\n",
    "- generate text using a character-based RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝을 이용한 텍스트 생성 워크플로우(workflow)\n",
    "- 1. 셰익스피어 텍스트 파일(shakespeare.txt) 얻기\n",
    "- 2. 텍스트의 문자를 숫자id로 치환하고 모델의 목적에 맞게 입출력 시퀀스로 변환\n",
    "- 3. RNN(Recurrent Neural Network)을 통한 텍스트 생성\n",
    "\n",
    "### 텍스트 생성 RNN기반 모델\n",
    "- 모델은 캐릭터(문자) 기반입니다. 훈련이 시작되었을 때 모델은 영어 단어의 철자법을 몰랐거나 단어가 텍스트의 단위라는 것도 몰랐습니다.\n",
    "- 출력 구조는 연극과 유사합니다. 텍스트 블록은 일반적으로 데이터셋과 유사한 모든 대문자로 화자 이름으로 시작합니다.\n",
    "- 이 모델은 작은 배치의 텍스트(각각 100자)에 대해 학습되며 일관된 구조로 더 긴 텍스트 시퀀스를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:34.822914Z",
     "iopub.status.busy": "2022-03-29T12:04:34.822455Z",
     "iopub.status.idle": "2022-03-29T12:04:36.803546Z",
     "shell.execute_reply": "2022-03-29T12:04:36.802868Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 데이터셋 준비(Data Setup)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_target_path = './meta_data'\n",
    "os.makedirs(zip_target_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.zip 파일을 dataset 폴더에 압축을 풀어준다.\n",
    "zip_source_path = './dataset.zip'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_source_path)\n",
    "extract_zip_file.extractall(zip_target_path)\n",
    " \n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = os.path.join(zip_target_path, 'dataset/shakespeare.txt')\n",
    "\n",
    "# 데이터 불러오기\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 데이터 전처리(Data Preprocessing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:38.252501Z",
     "iopub.status.busy": "2022-03-29T12:04:38.252311Z",
     "iopub.status.idle": "2022-03-29T12:04:38.257567Z",
     "shell.execute_reply": "2022-03-29T12:04:38.257070Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [],
   "source": [
    "# 어휘묶음 생성\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "# chars를 숫자id로 변경하는 StringLookup layer\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "# 숫자id를 chars로 변경하는 StringLookup layer\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:39.962063Z",
     "iopub.status.busy": "2022-03-29T12:04:39.961652Z",
     "iopub.status.idle": "2022-03-29T12:04:40.352538Z",
     "shell.execute_reply": "2022-03-29T12:04:40.351878Z"
    },
    "id": "UopbsKi88tm5"
   },
   "outputs": [],
   "source": [
    "# train예제 및 target 만들기\n",
    "# 각 입력 시퀀스에 대해 해당 대상은 한 문자를 오른쪽으로 이동한 것을 제외하고 동일한 길이의 텍스트를 포함한다.\n",
    "# 예시 : seq_length는 4이고 텍스트는 \"Hello\"인 경우\n",
    "#        입력 시퀀스는 \"Hell\"이고, target 시퀀스는 \"ello\"\n",
    "\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "# 여기서 시퀀스 길이는 100\n",
    "seq_length = 100\n",
    "# examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:40.416533Z",
     "iopub.status.busy": "2022-03-29T12:04:40.416053Z",
     "iopub.status.idle": "2022-03-29T12:04:40.419238Z",
     "shell.execute_reply": "2022-03-29T12:04:40.418579Z"
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "# 시퀀스를 입력으로 받아 복제하고 입력과 라벨을 정렬하는 함수\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:40.429495Z",
     "iopub.status.busy": "2022-03-29T12:04:40.429128Z",
     "iopub.status.idle": "2022-03-29T12:04:40.474507Z",
     "shell.execute_reply": "2022-03-29T12:04:40.473983Z"
    },
    "id": "B9iKPXkw5xwa"
   },
   "outputs": [],
   "source": [
    "# 입력시퀀스에 따른 타겟시퀀스 생성하고 이를 dataset에 저장\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:40.503055Z",
     "iopub.status.busy": "2022-03-29T12:04:40.502527Z",
     "iopub.status.idle": "2022-03-29T12:04:40.510116Z",
     "shell.execute_reply": "2022-03-29T12:04:40.509506Z"
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 학습 모델 훈련(Train Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:40.513485Z",
     "iopub.status.busy": "2022-03-29T12:04:40.513004Z",
     "iopub.status.idle": "2022-03-29T12:04:40.515997Z",
     "shell.execute_reply": "2022-03-29T12:04:40.515400Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 게이트 순환 유닛(Gated Recurrent Unit, GRU)\n",
    " - GRU(Gated Recurrent Unit)는 2014년 뉴욕대학교 조경현 교수님이 집필한 논문에서 제안되었습니다.\n",
    " - GRU는 LSTM의 장기 의존성 문제에 대한 해결책을 유지하면서, hidden state를 업데이트하는 계산을 줄였습니다.\n",
    " - 다시 말해서, GRU는 성능은 LSTM과 유사하면서 복잡했던 LSTM의 구조를 간단화 시켰습니다.\n",
    " \n",
    "### RNN, LSTM, GRU\n",
    " * RNN  \n",
    " RNN은 이전 타임 스텝에서의 어떠한 정보(hidden state)를 다음 타임스텝으로 계속 전달하여 연산하는 방식입니다.  \n",
    " 하지만 RNN의 경우 시퀀스가 너무 길다면 앞 쪽의 타임 스텝의 정보가 뒤에 있는 타입스텝까지 충분히 전달되지 못하는 문제가 있습니다.  \n",
    " 이를 장기 의존성 문제(long-term dependecies)라고 정리했습니다. LSTM과 GRU는 RNN의 이러한 문제점을 개선하고자 나온 모델입니다.  \n",
    "\n",
    "\n",
    " * LSTM(Long Short term Memory)  \n",
    " LSTM은 hidden state만이 아니라 cell state라는 역할이 있으며 Forget gate, Input gate, Output gate를 통해 계산이 이루어집니다.  \n",
    " gate 이름에서 알 수 있듯이 어떤 정보를 잊을지 유지할지를 선택하여 long-term과 short-term에 대한 정보를 고려할 수 있습니다.  \n",
    " cell state의 업데이트는 각 gate의 결과를 더함으로써 진행하는데 이는 시퀀스가 길더라도 gradient, 즉 오차를 상대적으로 잘 전파할 수 있도록 합니다.\n",
    " \n",
    " \n",
    " * LSTM과 GRU  \n",
    " GRU와 LSTM 중 어떤 것이 모델의 성능면에서 더 낫다라고 단정지어 말할 수 없으며,  \n",
    "기존에 LSTM을 사용하면서 최적의 하이퍼파라미터를 찾아낸 상황이라면 굳이 GRU로 바꿔서 사용할 필요는 없습니다.  \n",
    "경험적으로 데이터 양이 적을 때는 매개 변수의 양이 적은 GRU가 조금 더 낫고, 데이터 양이 더 많으면 LSTM이 더 낫다고도 합니다.  \n",
    "GRU보다 LSTM에 대한 연구나 사용량이 더 많은데, 이는 LSTM이 더 먼저 나온 구조이기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:40.519035Z",
     "iopub.status.busy": "2022-03-29T12:04:40.518579Z",
     "iopub.status.idle": "2022-03-29T12:04:40.524333Z",
     "shell.execute_reply": "2022-03-29T12:04:40.523677Z"
    },
    "id": "wj8HQ2w8z4iO"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "    \n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:40.527421Z",
     "iopub.status.busy": "2022-03-29T12:04:40.527023Z",
     "iopub.status.idle": "2022-03-29T12:04:40.540670Z",
     "shell.execute_reply": "2022-03-29T12:04:40.540151Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:43.547927Z",
     "iopub.status.busy": "2022-03-29T12:04:43.547512Z",
     "iopub.status.idle": "2022-03-29T12:04:43.550789Z",
     "shell.execute_reply": "2022-03-29T12:04:43.550278Z"
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './meta_data/training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"last_ckpt\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:43.553927Z",
     "iopub.status.busy": "2022-03-29T12:04:43.553400Z",
     "iopub.status.idle": "2022-03-29T12:04:43.556240Z",
     "shell.execute_reply": "2022-03-29T12:04:43.555725Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:04:43.559198Z",
     "iopub.status.busy": "2022-03-29T12:04:43.558716Z",
     "iopub.status.idle": "2022-03-29T12:06:31.473361Z",
     "shell.execute_reply": "2022-03-29T12:06:31.472701Z"
    },
    "id": "UK-hmKjYVoll",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "172/172 [==============================] - 16s 66ms/step - loss: 2.7251\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 12s 67ms/step - loss: 1.9918\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.7194\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 12s 67ms/step - loss: 1.5575\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.4572\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.3889\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.3368\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 12s 67ms/step - loss: 1.2920\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.2510\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.2127\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.1738\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.1342\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.0925\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 1.0477\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 1.0008\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.9516\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.9003\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.8479\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.7966\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.7471\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.7002\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.6576\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.6188\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.5859\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.5600\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.5361\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.5154\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 12s 66ms/step - loss: 0.4973\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4852\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4724\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4628\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4535\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4434\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4421\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4344\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4280\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4276\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4210\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4183\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4176\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 12s 64ms/step - loss: 0.4190\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4121\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 12s 64ms/step - loss: 0.4122\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4109\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4100\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4073\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 12s 65ms/step - loss: 0.4046\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 12s 64ms/step - loss: 0.4114\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 12s 64ms/step - loss: 0.4140\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 12s 64ms/step - loss: 0.4117\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy and loss curves for both training and validation data\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.plot(loss, label='Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 추론(Inference)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:06:31.477418Z",
     "iopub.status.busy": "2022-03-29T12:06:31.477017Z",
     "iopub.status.idle": "2022-03-29T12:06:31.485553Z",
     "shell.execute_reply": "2022-03-29T12:06:31.485020Z"
    },
    "id": "iSBU1tHmlUSs"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "    \n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "  \n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "    \n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                              return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "        \n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "    \n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "    \n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_test_target_path = './meta_data'\n",
    "os.makedirs(zip_test_target_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.zip 파일을 test_dataset 폴더에 압축을 풀어준다.\n",
    "zip_test_source_path = './test_dataset.zip'\n",
    "\n",
    "extract_zip_file = zipfile.ZipFile(zip_test_source_path)\n",
    "extract_zip_file.extractall(zip_test_target_path)\n",
    "\n",
    "extract_zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod test data\n",
    "test_files = glob(os.path.join(zip_test_target_path, 'test_dataset/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for test_file in test_files:\n",
    "    with open(test_file, 'r') as f:\n",
    "        test_data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T12:06:42.111175Z",
     "iopub.status.busy": "2022-03-29T12:06:42.110656Z",
     "iopub.status.idle": "2022-03-29T12:06:42.639806Z",
     "shell.execute_reply": "2022-03-29T12:06:42.639175Z"
    },
    "id": "_Z9bb_wX6Uuu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inference(next_char):\n",
    "    states = None\n",
    "\n",
    "    result = [next_char]\n",
    "\n",
    "    for n in range(100):\n",
    "        next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "        result.append(next_char)\n",
    "\n",
    "    return tf.strings.join(result)[0].numpy().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ inference ############\n",
      "ROMEO: My Secial to him.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Good awhile the Welshmen, old Lancaster,\n",
      "Deformed for a piece of beau \n",
      "\n",
      "\n",
      "############ inference ############\n",
      "JULIET: I pray, good friends, Grumio,\n",
      "Now is the father's name; I have with her child\n",
      "play to my stads, and  \n",
      "\n",
      "\n",
      "############ inference ############\n",
      "ROMEO: I am unrever'd from a weel.\n",
      "\n",
      "DUKE OF YORK:\n",
      "\n",
      "HASTINGS:\n",
      "Good father, child, quick, do you the common,\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in test_data:\n",
    "    print('############ inference ############')\n",
    "    next_char = tf.constant([data])\n",
    "    print(inference(next_char), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
